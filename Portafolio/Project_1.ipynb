{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raquel Senior\n",
    "# Assignement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness_level</th>\n",
       "      <th>Country or region</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Finland</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Norway</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very High</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Happiness_level Country or region  GDP per capita  Social support  \\\n",
       "0       Very High           Finland           1.340           1.587   \n",
       "1       Very High           Denmark           1.383           1.573   \n",
       "2       Very High            Norway           1.488           1.582   \n",
       "3       Very High           Iceland           1.380           1.624   \n",
       "4       Very High       Netherlands           1.396           1.522   \n",
       "\n",
       "   Healthy life expectancy  Freedom to make life choices  Generosity  \\\n",
       "0                    0.986                         0.596       0.153   \n",
       "1                    0.996                         0.592       0.252   \n",
       "2                    1.028                         0.603       0.271   \n",
       "3                    1.026                         0.591       0.354   \n",
       "4                    0.999                         0.557       0.322   \n",
       "\n",
       "   Perceptions of corruption  \n",
       "0                      0.393  \n",
       "1                      0.410  \n",
       "2                      0.341  \n",
       "3                      0.118  \n",
       "4                      0.298  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df= pd.read_csv(\"/Users/raquelsenior/Desktop/QMSS/Adv_ML/worldhappiness2019.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_region = pd.read_csv(\"/Users/raquelsenior/Desktop/QMSS/Adv_ML/region.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_region.head()\n",
    "pd.api.types.is_string_dtype(df_region['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness_level</th>\n",
       "      <th>GDP per capita</th>\n",
       "      <th>Social support</th>\n",
       "      <th>Healthy life expectancy</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Perceptions of corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.340</td>\n",
       "      <td>1.587</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.393</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.383</td>\n",
       "      <td>1.573</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.410</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.488</td>\n",
       "      <td>1.582</td>\n",
       "      <td>1.028</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.341</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.380</td>\n",
       "      <td>1.624</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.118</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.522</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.298</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.452</td>\n",
       "      <td>1.526</td>\n",
       "      <td>1.052</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.343</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.387</td>\n",
       "      <td>1.487</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.373</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.303</td>\n",
       "      <td>1.557</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.380</td>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.365</td>\n",
       "      <td>1.505</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.308</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.376</td>\n",
       "      <td>1.475</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.226</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.372</td>\n",
       "      <td>1.548</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.290</td>\n",
       "      <td>Oceania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.093</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.276</td>\n",
       "      <td>1.455</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.082</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.479</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.316</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.538</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.278</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.499</td>\n",
       "      <td>1.553</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.310</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.373</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.265</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.356</td>\n",
       "      <td>1.504</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.210</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.433</td>\n",
       "      <td>1.457</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.128</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.269</td>\n",
       "      <td>1.487</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.036</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.503</td>\n",
       "      <td>1.310</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.182</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.300</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.151</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.070</td>\n",
       "      <td>1.323</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.073</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.324</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.045</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.183</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.368</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.097</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.159</td>\n",
       "      <td>1.369</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.056</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Very High</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.269</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.535</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.078</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.403</td>\n",
       "      <td>1.357</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.132</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.684</td>\n",
       "      <td>1.313</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.167</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Very High</td>\n",
       "      <td>1.286</td>\n",
       "      <td>1.484</td>\n",
       "      <td>1.062</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.079</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.053</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.385</td>\n",
       "      <td>1.105</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.052</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.045</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.265</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.047</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.566</td>\n",
       "      <td>0.172</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.174</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.078</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.820</td>\n",
       "      <td>1.390</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.010</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.336</td>\n",
       "      <td>1.033</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.209</td>\n",
       "      <td>0.100</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.811</td>\n",
       "      <td>1.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.135</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.332</td>\n",
       "      <td>1.069</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.060</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.913</td>\n",
       "      <td>1.039</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.067</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.087</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.085</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.085</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.033</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.078</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.041</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.489</td>\n",
       "      <td>1.169</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.093</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.180</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.366</td>\n",
       "      <td>1.114</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.089</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.110</td>\n",
       "      <td>Americas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>1.041</td>\n",
       "      <td>1.145</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.100</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.141</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.089</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.287</td>\n",
       "      <td>1.163</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.077</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.411</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.147</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.025</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.035</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Very Low</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.202</td>\n",
       "      <td>0.091</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Happiness_level  GDP per capita  Social support  Healthy life expectancy  \\\n",
       "0         Very High           1.340           1.587                    0.986   \n",
       "1         Very High           1.383           1.573                    0.996   \n",
       "2         Very High           1.488           1.582                    1.028   \n",
       "3         Very High           1.380           1.624                    1.026   \n",
       "4         Very High           1.396           1.522                    0.999   \n",
       "5         Very High           1.452           1.526                    1.052   \n",
       "6         Very High           1.387           1.487                    1.009   \n",
       "7         Very High           1.303           1.557                    1.026   \n",
       "8         Very High           1.365           1.505                    1.039   \n",
       "9         Very High           1.376           1.475                    1.016   \n",
       "10        Very High           1.372           1.548                    1.036   \n",
       "11        Very High           1.034           1.441                    0.963   \n",
       "12        Very High           1.276           1.455                    1.029   \n",
       "13        Very High           1.609           1.479                    1.012   \n",
       "14        Very High           1.333           1.538                    0.996   \n",
       "15        Very High           1.499           1.553                    0.999   \n",
       "16        Very High           1.373           1.454                    0.987   \n",
       "17        Very High           1.356           1.504                    0.986   \n",
       "18        Very High           1.433           1.457                    0.874   \n",
       "19        Very High           1.269           1.487                    0.920   \n",
       "20        Very High           1.503           1.310                    0.825   \n",
       "21        Very High           1.300           1.520                    0.999   \n",
       "22        Very High           1.070           1.323                    0.861   \n",
       "23        Very High           1.324           1.472                    1.045   \n",
       "24        Very High           1.368           1.430                    0.914   \n",
       "25        Very High           1.159           1.369                    0.920   \n",
       "26        Very High           0.800           1.269                    0.746   \n",
       "27        Very High           1.403           1.357                    0.795   \n",
       "28        Very High           1.684           1.313                    0.871   \n",
       "29        Very High           1.286           1.484                    1.062   \n",
       "..              ...             ...             ...                      ...   \n",
       "126        Very Low           0.094           1.125                    0.357   \n",
       "127        Very Low           0.385           1.105                    0.308   \n",
       "128        Very Low           0.268           0.841                    0.242   \n",
       "129        Very Low           0.949           1.265                    0.831   \n",
       "130        Very Low           0.710           1.181                    0.555   \n",
       "131        Very Low           0.350           0.766                    0.192   \n",
       "132        Very Low           0.820           1.390                    0.739   \n",
       "133        Very Low           0.336           1.033                    0.532   \n",
       "134        Very Low           0.811           1.149                    0.000   \n",
       "135        Very Low           0.332           1.069                    0.443   \n",
       "136        Very Low           0.913           1.039                    0.644   \n",
       "137        Very Low           0.578           1.058                    0.426   \n",
       "138        Very Low           0.275           0.572                    0.410   \n",
       "139        Very Low           0.755           0.765                    0.588   \n",
       "140        Very Low           0.073           0.922                    0.443   \n",
       "141        Very Low           0.274           0.757                    0.505   \n",
       "142        Very Low           0.274           0.916                    0.555   \n",
       "143        Very Low           0.489           1.169                    0.168   \n",
       "144        Very Low           0.046           0.447                    0.380   \n",
       "145        Very Low           0.366           1.114                    0.433   \n",
       "146        Very Low           0.323           0.688                    0.449   \n",
       "147        Very Low           1.041           1.145                    0.538   \n",
       "148        Very Low           0.619           0.378                    0.440   \n",
       "149        Very Low           0.191           0.560                    0.495   \n",
       "150        Very Low           0.287           1.163                    0.463   \n",
       "151        Very Low           0.359           0.711                    0.614   \n",
       "152        Very Low           0.476           0.885                    0.499   \n",
       "153        Very Low           0.350           0.517                    0.361   \n",
       "154        Very Low           0.026           0.000                    0.105   \n",
       "155        Very Low           0.306           0.575                    0.295   \n",
       "\n",
       "     Freedom to make life choices  Generosity  Perceptions of corruption  \\\n",
       "0                           0.596       0.153                      0.393   \n",
       "1                           0.592       0.252                      0.410   \n",
       "2                           0.603       0.271                      0.341   \n",
       "3                           0.591       0.354                      0.118   \n",
       "4                           0.557       0.322                      0.298   \n",
       "5                           0.572       0.263                      0.343   \n",
       "6                           0.574       0.267                      0.373   \n",
       "7                           0.585       0.330                      0.380   \n",
       "8                           0.584       0.285                      0.308   \n",
       "9                           0.532       0.244                      0.226   \n",
       "10                          0.557       0.332                      0.290   \n",
       "11                          0.558       0.144                      0.093   \n",
       "12                          0.371       0.261                      0.082   \n",
       "13                          0.526       0.194                      0.316   \n",
       "14                          0.450       0.348                      0.278   \n",
       "15                          0.516       0.298                      0.310   \n",
       "16                          0.495       0.261                      0.265   \n",
       "17                          0.473       0.160                      0.210   \n",
       "18                          0.454       0.280                      0.128   \n",
       "19                          0.457       0.046                      0.036   \n",
       "20                          0.598       0.262                      0.182   \n",
       "21                          0.564       0.375                      0.151   \n",
       "22                          0.433       0.074                      0.073   \n",
       "23                          0.436       0.111                      0.183   \n",
       "24                          0.351       0.242                      0.097   \n",
       "25                          0.357       0.187                      0.056   \n",
       "26                          0.535       0.175                      0.078   \n",
       "27                          0.439       0.080                      0.132   \n",
       "28                          0.555       0.220                      0.167   \n",
       "29                          0.362       0.153                      0.079   \n",
       "..                            ...         ...                        ...   \n",
       "126                         0.269       0.212                      0.053   \n",
       "127                         0.327       0.153                      0.052   \n",
       "128                         0.309       0.252                      0.045   \n",
       "129                         0.470       0.244                      0.047   \n",
       "130                         0.525       0.566                      0.172   \n",
       "131                         0.174       0.198                      0.078   \n",
       "132                         0.178       0.187                      0.010   \n",
       "133                         0.344       0.209                      0.100   \n",
       "134                         0.313       0.074                      0.135   \n",
       "135                         0.356       0.252                      0.060   \n",
       "136                         0.241       0.076                      0.067   \n",
       "137                         0.431       0.247                      0.087   \n",
       "138                         0.293       0.177                      0.085   \n",
       "139                         0.498       0.200                      0.085   \n",
       "140                         0.370       0.233                      0.033   \n",
       "141                         0.142       0.275                      0.078   \n",
       "142                         0.148       0.169                      0.041   \n",
       "143                         0.359       0.107                      0.093   \n",
       "144                         0.220       0.176                      0.180   \n",
       "145                         0.361       0.151                      0.089   \n",
       "146                         0.026       0.419                      0.110   \n",
       "147                         0.455       0.025                      0.100   \n",
       "148                         0.013       0.331                      0.141   \n",
       "149                         0.443       0.218                      0.089   \n",
       "150                         0.143       0.108                      0.077   \n",
       "151                         0.555       0.217                      0.411   \n",
       "152                         0.417       0.276                      0.147   \n",
       "153                         0.000       0.158                      0.025   \n",
       "154                         0.225       0.235                      0.035   \n",
       "155                         0.010       0.202                      0.091   \n",
       "\n",
       "       region  \n",
       "0      Europe  \n",
       "1      Europe  \n",
       "2      Europe  \n",
       "3      Europe  \n",
       "4      Europe  \n",
       "5      Europe  \n",
       "6      Europe  \n",
       "7     Oceania  \n",
       "8    Americas  \n",
       "9      Europe  \n",
       "10    Oceania  \n",
       "11   Americas  \n",
       "12       Asia  \n",
       "13     Europe  \n",
       "14     Europe  \n",
       "15     Europe  \n",
       "16     Europe  \n",
       "17     Europe  \n",
       "18   Americas  \n",
       "19     Europe  \n",
       "20       Asia  \n",
       "21     Europe  \n",
       "22   Americas  \n",
       "23     Europe  \n",
       "24       Asia  \n",
       "25   Americas  \n",
       "26   Americas  \n",
       "27       Asia  \n",
       "28       Asia  \n",
       "29     Europe  \n",
       "..        ...  \n",
       "126    Africa  \n",
       "127    Africa  \n",
       "128    Africa  \n",
       "129      Asia  \n",
       "130      Asia  \n",
       "131    Africa  \n",
       "132    Europe  \n",
       "133    Africa  \n",
       "134    Africa  \n",
       "135    Africa  \n",
       "136    Africa  \n",
       "137    Africa  \n",
       "138    Africa  \n",
       "139      Asia  \n",
       "140    Africa  \n",
       "141    Africa  \n",
       "142    Africa  \n",
       "143    Africa  \n",
       "144    Africa  \n",
       "145    Africa  \n",
       "146  Americas  \n",
       "147    Africa  \n",
       "148      Asia  \n",
       "149    Africa  \n",
       "150      Asia  \n",
       "151    Africa  \n",
       "152    Africa  \n",
       "153      Asia  \n",
       "154    Africa  \n",
       "155    Africa  \n",
       "\n",
       "[156 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedata=pd.merge(df, df_region, how='left', left_on='Country or region', right_on='name')\n",
    "# Check for missing values (there won't be any given that I have already cleaned up the region data)\n",
    "mergedata.loc[pd.isnull(mergedata).iloc[:,9]].to_csv(\"missing.csv\",index=False)\n",
    "\n",
    "# clean up final region data\n",
    "# data=mergedata.drop(['Happiness_level'],axis=1)\n",
    "data=mergedata.drop(['name'],axis=1)\n",
    "data=data.drop(['Country or region'],axis=1)\n",
    "data=data.drop(['sub-region'],axis=1)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=\"GDP per capita\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Social support\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Healthy life expectancy\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Freedom to make life choices\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Generosity\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"Perceptions of corruption\", y=\"Happiness_level\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 7)\n",
      "(117,)\n",
      "['GDP per capita', 'Social support', 'Healthy life expectancy', 'Freedom to make life choices', 'Generosity', 'Perceptions of corruption', 'region']\n"
     ]
    }
   ],
   "source": [
    "# Set up training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y=data['Happiness_level']\n",
    "X=data.drop(['Happiness_level'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "\n",
    "numeric_features=X.columns.tolist()\n",
    "numeric_features.remove('region')\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['region']\n",
    "\n",
    "#Replacing missing values with Modal value and then one hot encoding.\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# final preprocessor object set up with ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "\n",
    "#Fit your preprocessor object\n",
    "prediction_input_preprocessor=preprocessor.fit(X_train) \n",
    "\n",
    "import pickle\n",
    "pickle.dump(prediction_input_preprocessor, open( \"preprocessor.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape for keras input:\n",
    "prediction_input_preprocessor.transform(X_train).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape for keras output:\n",
    "pd.get_dummies(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20407471 0.16970883 0.18155172 0.13411991 0.09711037 0.13401045\n",
      " 0.02317548 0.02060729 0.02129561 0.01394199 0.00040364]\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection: Random forest \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=200)\n",
    "formodel = forest.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train))\n",
    "\n",
    "\n",
    "print(formodel.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raquelsenior/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/_base.py:81: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "sfm = SelectFromModel(formodel, threshold=.25)\n",
    "sfm.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train))\n",
    "Xtrain_new = sfm.transform(prediction_input_preprocessor.transform(X_train)) # transform data to insert into new model\n",
    "\n",
    "print(prediction_input_preprocessor.transform(X_train).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, no variables were dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raquelsenior/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection: Lasso \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lasso = LogisticRegression(penalty='l1', solver='saga')\n",
    "lasso.fit(prediction_input_preprocessor.transform(X_train), y_train)\n",
    "\n",
    "model = SelectFromModel(lasso, prefit=True)\n",
    "\n",
    "X_new = model.transform(prediction_input_preprocessor.transform(X_train))\n",
    "print(X_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case above, two variables were selected. So, Lasso \"zeroed out\" 2 features of the original 11 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting model: KNN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skfold = StratifiedKFold() \n",
    "\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "\n",
    "\n",
    "knn_param_grid = {'kneighborsclassifier__n_neighbors': range(1, 10)} # remember, use two underscores before n, \"__n\"\n",
    "knn_grid = GridSearchCV(knn_pipe, knn_param_grid, cv=skfold).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"KNN for CLASSIFICATION\")\n",
    "print(\"Test set Score: {:.2f}\".format(knn_grid.score(X_test, y_test)))\n",
    "print(\"Best Cross-Validation Score: {:.2f}\".format(knn_grid.best_score_))\n",
    "print(\"Best Parameter: {}\".format(knn_grid.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "KNN for CLASSIFICATION\n",
    "\n",
    "Test set Score: 0.04\n",
    "\n",
    "Best Parameter: {'kneighborsregressor__n_neighbors': 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation suggest that k=9 is the best parameter for this KNN regression, which yields an average accuracy score of 4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier's cross validation accuracy: 0.6242424242424243\n",
      "Random Forest Classifier's Test-Data prediction accuracy: 0.41026\n"
     ]
    }
   ],
   "source": [
    "# Prediction model: Random forest\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "\n",
    "model=RandomForestClassifier(n_estimators=1000, random_state = 4)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "model.fit(prediction_input_preprocessor.transform(X_train), y_train)\n",
    "y_pred=model.predict(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "print(\"Random Forest Classifier's cross validation accuracy:\", np.mean(cross_val_score(model, prediction_input_preprocessor.transform(X_train), y_train, cv=10)))\n",
    "print(\"Random Forest Classifier's Test-Data prediction accuracy: {:.5f}\".format(model.score(prediction_input_preprocessor.transform(X_test), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 93 samples, validate on 24 samples\n",
      "Epoch 1/300\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 1.5841 - accuracy: 0.2581 - val_loss: 1.6384 - val_accuracy: 0.0833\n",
      "Epoch 2/300\n",
      "93/93 [==============================] - 0s 200us/step - loss: 1.5826 - accuracy: 0.2581 - val_loss: 1.6381 - val_accuracy: 0.0833\n",
      "Epoch 3/300\n",
      "93/93 [==============================] - 0s 190us/step - loss: 1.5812 - accuracy: 0.2796 - val_loss: 1.6379 - val_accuracy: 0.0833\n",
      "Epoch 4/300\n",
      "93/93 [==============================] - 0s 175us/step - loss: 1.5797 - accuracy: 0.2796 - val_loss: 1.6379 - val_accuracy: 0.0833\n",
      "Epoch 5/300\n",
      "93/93 [==============================] - 0s 147us/step - loss: 1.5783 - accuracy: 0.2688 - val_loss: 1.6373 - val_accuracy: 0.1250\n",
      "Epoch 6/300\n",
      "93/93 [==============================] - 0s 154us/step - loss: 1.5762 - accuracy: 0.2796 - val_loss: 1.6370 - val_accuracy: 0.1250\n",
      "Epoch 7/300\n",
      "93/93 [==============================] - 0s 133us/step - loss: 1.5747 - accuracy: 0.2796 - val_loss: 1.6367 - val_accuracy: 0.1250\n",
      "Epoch 8/300\n",
      "93/93 [==============================] - 0s 90us/step - loss: 1.5734 - accuracy: 0.2903 - val_loss: 1.6362 - val_accuracy: 0.1667\n",
      "Epoch 9/300\n",
      "93/93 [==============================] - 0s 106us/step - loss: 1.5721 - accuracy: 0.3118 - val_loss: 1.6362 - val_accuracy: 0.1667\n",
      "Epoch 10/300\n",
      "93/93 [==============================] - 0s 139us/step - loss: 1.5705 - accuracy: 0.3118 - val_loss: 1.6359 - val_accuracy: 0.1667\n",
      "Epoch 11/300\n",
      "93/93 [==============================] - 0s 259us/step - loss: 1.5691 - accuracy: 0.3118 - val_loss: 1.6357 - val_accuracy: 0.1667\n",
      "Epoch 12/300\n",
      "93/93 [==============================] - 0s 112us/step - loss: 1.5676 - accuracy: 0.3011 - val_loss: 1.6356 - val_accuracy: 0.1667\n",
      "Epoch 13/300\n",
      "93/93 [==============================] - 0s 298us/step - loss: 1.5664 - accuracy: 0.3118 - val_loss: 1.6354 - val_accuracy: 0.2083\n",
      "Epoch 14/300\n",
      "93/93 [==============================] - 0s 187us/step - loss: 1.5651 - accuracy: 0.3011 - val_loss: 1.6352 - val_accuracy: 0.2083\n",
      "Epoch 15/300\n",
      "93/93 [==============================] - 0s 243us/step - loss: 1.5639 - accuracy: 0.3118 - val_loss: 1.6351 - val_accuracy: 0.2083\n",
      "Epoch 16/300\n",
      "93/93 [==============================] - 0s 115us/step - loss: 1.5628 - accuracy: 0.3011 - val_loss: 1.6348 - val_accuracy: 0.2083\n",
      "Epoch 17/300\n",
      "93/93 [==============================] - 0s 122us/step - loss: 1.5616 - accuracy: 0.3118 - val_loss: 1.6345 - val_accuracy: 0.2083\n",
      "Epoch 18/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.5604 - accuracy: 0.3011 - val_loss: 1.6340 - val_accuracy: 0.1667\n",
      "Epoch 19/300\n",
      "93/93 [==============================] - 0s 183us/step - loss: 1.5593 - accuracy: 0.3118 - val_loss: 1.6338 - val_accuracy: 0.1667\n",
      "Epoch 20/300\n",
      "93/93 [==============================] - 0s 213us/step - loss: 1.5582 - accuracy: 0.3226 - val_loss: 1.6336 - val_accuracy: 0.1667\n",
      "Epoch 21/300\n",
      "93/93 [==============================] - 0s 108us/step - loss: 1.5570 - accuracy: 0.3226 - val_loss: 1.6334 - val_accuracy: 0.1667\n",
      "Epoch 22/300\n",
      "93/93 [==============================] - 0s 95us/step - loss: 1.5558 - accuracy: 0.3226 - val_loss: 1.6333 - val_accuracy: 0.1667\n",
      "Epoch 23/300\n",
      "93/93 [==============================] - 0s 209us/step - loss: 1.5548 - accuracy: 0.3226 - val_loss: 1.6330 - val_accuracy: 0.1667\n",
      "Epoch 24/300\n",
      "93/93 [==============================] - 0s 118us/step - loss: 1.5536 - accuracy: 0.3226 - val_loss: 1.6328 - val_accuracy: 0.1667\n",
      "Epoch 25/300\n",
      "93/93 [==============================] - 0s 161us/step - loss: 1.5526 - accuracy: 0.3118 - val_loss: 1.6325 - val_accuracy: 0.1667\n",
      "Epoch 26/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.5515 - accuracy: 0.3011 - val_loss: 1.6322 - val_accuracy: 0.1667\n",
      "Epoch 27/300\n",
      "93/93 [==============================] - 0s 186us/step - loss: 1.5504 - accuracy: 0.3226 - val_loss: 1.6320 - val_accuracy: 0.1667\n",
      "Epoch 28/300\n",
      "93/93 [==============================] - 0s 120us/step - loss: 1.5493 - accuracy: 0.3011 - val_loss: 1.6316 - val_accuracy: 0.1667\n",
      "Epoch 29/300\n",
      "93/93 [==============================] - 0s 100us/step - loss: 1.5482 - accuracy: 0.3118 - val_loss: 1.6314 - val_accuracy: 0.1667\n",
      "Epoch 30/300\n",
      "93/93 [==============================] - 0s 292us/step - loss: 1.5471 - accuracy: 0.3226 - val_loss: 1.6312 - val_accuracy: 0.1667\n",
      "Epoch 31/300\n",
      "93/93 [==============================] - 0s 149us/step - loss: 1.5460 - accuracy: 0.3226 - val_loss: 1.6311 - val_accuracy: 0.1667\n",
      "Epoch 32/300\n",
      "93/93 [==============================] - 0s 200us/step - loss: 1.5447 - accuracy: 0.3333 - val_loss: 1.6305 - val_accuracy: 0.2083\n",
      "Epoch 33/300\n",
      "93/93 [==============================] - 0s 140us/step - loss: 1.5435 - accuracy: 0.3333 - val_loss: 1.6301 - val_accuracy: 0.2083\n",
      "Epoch 34/300\n",
      "93/93 [==============================] - 0s 138us/step - loss: 1.5422 - accuracy: 0.3333 - val_loss: 1.6295 - val_accuracy: 0.2083\n",
      "Epoch 35/300\n",
      "93/93 [==============================] - 0s 177us/step - loss: 1.5406 - accuracy: 0.3226 - val_loss: 1.6289 - val_accuracy: 0.2083\n",
      "Epoch 36/300\n",
      "93/93 [==============================] - 0s 110us/step - loss: 1.5389 - accuracy: 0.3333 - val_loss: 1.6280 - val_accuracy: 0.2083\n",
      "Epoch 37/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.5370 - accuracy: 0.3333 - val_loss: 1.6273 - val_accuracy: 0.2083\n",
      "Epoch 38/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.5353 - accuracy: 0.3441 - val_loss: 1.6269 - val_accuracy: 0.1667\n",
      "Epoch 39/300\n",
      "93/93 [==============================] - 0s 181us/step - loss: 1.5335 - accuracy: 0.3441 - val_loss: 1.6262 - val_accuracy: 0.2083\n",
      "Epoch 40/300\n",
      "93/93 [==============================] - 0s 146us/step - loss: 1.5317 - accuracy: 0.3441 - val_loss: 1.6254 - val_accuracy: 0.2083\n",
      "Epoch 41/300\n",
      "93/93 [==============================] - 0s 173us/step - loss: 1.5301 - accuracy: 0.3441 - val_loss: 1.6247 - val_accuracy: 0.2083\n",
      "Epoch 42/300\n",
      "93/93 [==============================] - 0s 130us/step - loss: 1.5285 - accuracy: 0.3226 - val_loss: 1.6239 - val_accuracy: 0.2083\n",
      "Epoch 43/300\n",
      "93/93 [==============================] - 0s 145us/step - loss: 1.5268 - accuracy: 0.3441 - val_loss: 1.6233 - val_accuracy: 0.1667\n",
      "Epoch 44/300\n",
      "93/93 [==============================] - 0s 200us/step - loss: 1.5255 - accuracy: 0.3333 - val_loss: 1.6222 - val_accuracy: 0.1667\n",
      "Epoch 45/300\n",
      "93/93 [==============================] - 0s 137us/step - loss: 1.5236 - accuracy: 0.3548 - val_loss: 1.6218 - val_accuracy: 0.2083\n",
      "Epoch 46/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.5222 - accuracy: 0.3548 - val_loss: 1.6214 - val_accuracy: 0.2083\n",
      "Epoch 47/300\n",
      "93/93 [==============================] - 0s 108us/step - loss: 1.5206 - accuracy: 0.3548 - val_loss: 1.6210 - val_accuracy: 0.2083\n",
      "Epoch 48/300\n",
      "93/93 [==============================] - 0s 144us/step - loss: 1.5190 - accuracy: 0.3548 - val_loss: 1.6205 - val_accuracy: 0.2083\n",
      "Epoch 49/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.5175 - accuracy: 0.3548 - val_loss: 1.6200 - val_accuracy: 0.2083\n",
      "Epoch 50/300\n",
      "93/93 [==============================] - 0s 204us/step - loss: 1.5161 - accuracy: 0.3548 - val_loss: 1.6191 - val_accuracy: 0.2083\n",
      "Epoch 51/300\n",
      "93/93 [==============================] - 0s 145us/step - loss: 1.5139 - accuracy: 0.3656 - val_loss: 1.6187 - val_accuracy: 0.2083\n",
      "Epoch 52/300\n",
      "93/93 [==============================] - 0s 178us/step - loss: 1.5123 - accuracy: 0.3763 - val_loss: 1.6181 - val_accuracy: 0.2083\n",
      "Epoch 53/300\n",
      "93/93 [==============================] - 0s 187us/step - loss: 1.5107 - accuracy: 0.3763 - val_loss: 1.6175 - val_accuracy: 0.2083\n",
      "Epoch 54/300\n",
      "93/93 [==============================] - 0s 133us/step - loss: 1.5092 - accuracy: 0.3763 - val_loss: 1.6171 - val_accuracy: 0.2083\n",
      "Epoch 55/300\n",
      "93/93 [==============================] - 0s 121us/step - loss: 1.5076 - accuracy: 0.3763 - val_loss: 1.6169 - val_accuracy: 0.2083\n",
      "Epoch 56/300\n",
      "93/93 [==============================] - 0s 198us/step - loss: 1.5061 - accuracy: 0.3871 - val_loss: 1.6162 - val_accuracy: 0.2083\n",
      "Epoch 57/300\n",
      "93/93 [==============================] - 0s 108us/step - loss: 1.5043 - accuracy: 0.3871 - val_loss: 1.6156 - val_accuracy: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.5027 - accuracy: 0.3871 - val_loss: 1.6155 - val_accuracy: 0.2083\n",
      "Epoch 59/300\n",
      "93/93 [==============================] - 0s 145us/step - loss: 1.5008 - accuracy: 0.3871 - val_loss: 1.6149 - val_accuracy: 0.2083\n",
      "Epoch 60/300\n",
      "93/93 [==============================] - 0s 103us/step - loss: 1.4990 - accuracy: 0.3978 - val_loss: 1.6145 - val_accuracy: 0.2083\n",
      "Epoch 61/300\n",
      "93/93 [==============================] - 0s 95us/step - loss: 1.4972 - accuracy: 0.3978 - val_loss: 1.6140 - val_accuracy: 0.2083\n",
      "Epoch 62/300\n",
      "93/93 [==============================] - 0s 178us/step - loss: 1.4957 - accuracy: 0.4086 - val_loss: 1.6139 - val_accuracy: 0.2083\n",
      "Epoch 63/300\n",
      "93/93 [==============================] - 0s 128us/step - loss: 1.4940 - accuracy: 0.4086 - val_loss: 1.6134 - val_accuracy: 0.2083\n",
      "Epoch 64/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.4922 - accuracy: 0.4086 - val_loss: 1.6131 - val_accuracy: 0.2083\n",
      "Epoch 65/300\n",
      "93/93 [==============================] - 0s 154us/step - loss: 1.4904 - accuracy: 0.3978 - val_loss: 1.6126 - val_accuracy: 0.2083\n",
      "Epoch 66/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.4888 - accuracy: 0.3978 - val_loss: 1.6124 - val_accuracy: 0.2083\n",
      "Epoch 67/300\n",
      "93/93 [==============================] - 0s 134us/step - loss: 1.4872 - accuracy: 0.3871 - val_loss: 1.6121 - val_accuracy: 0.2083\n",
      "Epoch 68/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.4855 - accuracy: 0.3871 - val_loss: 1.6116 - val_accuracy: 0.2083\n",
      "Epoch 69/300\n",
      "93/93 [==============================] - 0s 164us/step - loss: 1.4838 - accuracy: 0.3978 - val_loss: 1.6113 - val_accuracy: 0.2083\n",
      "Epoch 70/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.4821 - accuracy: 0.3978 - val_loss: 1.6111 - val_accuracy: 0.2083\n",
      "Epoch 71/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.4805 - accuracy: 0.3978 - val_loss: 1.6111 - val_accuracy: 0.2083\n",
      "Epoch 72/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.4788 - accuracy: 0.4086 - val_loss: 1.6107 - val_accuracy: 0.2083\n",
      "Epoch 73/300\n",
      "93/93 [==============================] - 0s 153us/step - loss: 1.4772 - accuracy: 0.4086 - val_loss: 1.6108 - val_accuracy: 0.2083\n",
      "Epoch 74/300\n",
      "93/93 [==============================] - 0s 102us/step - loss: 1.4754 - accuracy: 0.4086 - val_loss: 1.6106 - val_accuracy: 0.2083\n",
      "Epoch 75/300\n",
      "93/93 [==============================] - 0s 161us/step - loss: 1.4736 - accuracy: 0.4086 - val_loss: 1.6101 - val_accuracy: 0.2083\n",
      "Epoch 76/300\n",
      "93/93 [==============================] - 0s 109us/step - loss: 1.4715 - accuracy: 0.4086 - val_loss: 1.6100 - val_accuracy: 0.2083\n",
      "Epoch 77/300\n",
      "93/93 [==============================] - 0s 149us/step - loss: 1.4696 - accuracy: 0.4086 - val_loss: 1.6098 - val_accuracy: 0.2083\n",
      "Epoch 78/300\n",
      "93/93 [==============================] - 0s 131us/step - loss: 1.4676 - accuracy: 0.4086 - val_loss: 1.6095 - val_accuracy: 0.2083\n",
      "Epoch 79/300\n",
      "93/93 [==============================] - 0s 133us/step - loss: 1.4656 - accuracy: 0.3978 - val_loss: 1.6091 - val_accuracy: 0.2083\n",
      "Epoch 80/300\n",
      "93/93 [==============================] - 0s 144us/step - loss: 1.4636 - accuracy: 0.4086 - val_loss: 1.6088 - val_accuracy: 0.2083\n",
      "Epoch 81/300\n",
      "93/93 [==============================] - 0s 109us/step - loss: 1.4615 - accuracy: 0.4086 - val_loss: 1.6081 - val_accuracy: 0.2083\n",
      "Epoch 82/300\n",
      "93/93 [==============================] - 0s 130us/step - loss: 1.4593 - accuracy: 0.4086 - val_loss: 1.6083 - val_accuracy: 0.2083\n",
      "Epoch 83/300\n",
      "93/93 [==============================] - 0s 148us/step - loss: 1.4572 - accuracy: 0.4086 - val_loss: 1.6080 - val_accuracy: 0.2083\n",
      "Epoch 84/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.4552 - accuracy: 0.3978 - val_loss: 1.6078 - val_accuracy: 0.2500\n",
      "Epoch 85/300\n",
      "93/93 [==============================] - 0s 122us/step - loss: 1.4530 - accuracy: 0.4086 - val_loss: 1.6074 - val_accuracy: 0.2500\n",
      "Epoch 86/300\n",
      "93/93 [==============================] - 0s 239us/step - loss: 1.4509 - accuracy: 0.4301 - val_loss: 1.6075 - val_accuracy: 0.2500\n",
      "Epoch 87/300\n",
      "93/93 [==============================] - 0s 114us/step - loss: 1.4487 - accuracy: 0.4194 - val_loss: 1.6072 - val_accuracy: 0.2083\n",
      "Epoch 88/300\n",
      "93/93 [==============================] - 0s 152us/step - loss: 1.4465 - accuracy: 0.4194 - val_loss: 1.6068 - val_accuracy: 0.2083\n",
      "Epoch 89/300\n",
      "93/93 [==============================] - 0s 111us/step - loss: 1.4447 - accuracy: 0.4301 - val_loss: 1.6068 - val_accuracy: 0.2083\n",
      "Epoch 90/300\n",
      "93/93 [==============================] - 0s 148us/step - loss: 1.4424 - accuracy: 0.4301 - val_loss: 1.6062 - val_accuracy: 0.2083\n",
      "Epoch 91/300\n",
      "93/93 [==============================] - 0s 218us/step - loss: 1.4405 - accuracy: 0.4301 - val_loss: 1.6061 - val_accuracy: 0.2083\n",
      "Epoch 92/300\n",
      "93/93 [==============================] - 0s 129us/step - loss: 1.4384 - accuracy: 0.4301 - val_loss: 1.6063 - val_accuracy: 0.2083\n",
      "Epoch 93/300\n",
      "93/93 [==============================] - 0s 165us/step - loss: 1.4363 - accuracy: 0.4301 - val_loss: 1.6061 - val_accuracy: 0.2083\n",
      "Epoch 94/300\n",
      "93/93 [==============================] - 0s 128us/step - loss: 1.4343 - accuracy: 0.4301 - val_loss: 1.6061 - val_accuracy: 0.2083\n",
      "Epoch 95/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.4323 - accuracy: 0.4301 - val_loss: 1.6060 - val_accuracy: 0.2083\n",
      "Epoch 96/300\n",
      "93/93 [==============================] - 0s 137us/step - loss: 1.4303 - accuracy: 0.4409 - val_loss: 1.6065 - val_accuracy: 0.2083\n",
      "Epoch 97/300\n",
      "93/93 [==============================] - 0s 134us/step - loss: 1.4283 - accuracy: 0.4409 - val_loss: 1.6063 - val_accuracy: 0.2083\n",
      "Epoch 98/300\n",
      "93/93 [==============================] - 0s 163us/step - loss: 1.4263 - accuracy: 0.4409 - val_loss: 1.6066 - val_accuracy: 0.2083\n",
      "Epoch 99/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.4241 - accuracy: 0.4409 - val_loss: 1.6064 - val_accuracy: 0.2083\n",
      "Epoch 100/300\n",
      "93/93 [==============================] - 0s 156us/step - loss: 1.4222 - accuracy: 0.4409 - val_loss: 1.6064 - val_accuracy: 0.2083\n",
      "Epoch 101/300\n",
      "93/93 [==============================] - 0s 119us/step - loss: 1.4201 - accuracy: 0.4409 - val_loss: 1.6062 - val_accuracy: 0.2083\n",
      "Epoch 102/300\n",
      "93/93 [==============================] - 0s 141us/step - loss: 1.4181 - accuracy: 0.4409 - val_loss: 1.6064 - val_accuracy: 0.2083\n",
      "Epoch 103/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.4161 - accuracy: 0.4409 - val_loss: 1.6062 - val_accuracy: 0.2083\n",
      "Epoch 104/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.4139 - accuracy: 0.4409 - val_loss: 1.6063 - val_accuracy: 0.2083\n",
      "Epoch 105/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.4119 - accuracy: 0.4409 - val_loss: 1.6063 - val_accuracy: 0.2083\n",
      "Epoch 106/300\n",
      "93/93 [==============================] - 0s 129us/step - loss: 1.4099 - accuracy: 0.4516 - val_loss: 1.6065 - val_accuracy: 0.2083\n",
      "Epoch 107/300\n",
      "93/93 [==============================] - 0s 131us/step - loss: 1.4077 - accuracy: 0.4516 - val_loss: 1.6065 - val_accuracy: 0.2083\n",
      "Epoch 108/300\n",
      "93/93 [==============================] - 0s 162us/step - loss: 1.4057 - accuracy: 0.4516 - val_loss: 1.6067 - val_accuracy: 0.2083\n",
      "Epoch 109/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.4035 - accuracy: 0.4516 - val_loss: 1.6070 - val_accuracy: 0.2083\n",
      "Epoch 110/300\n",
      "93/93 [==============================] - 0s 167us/step - loss: 1.4013 - accuracy: 0.4516 - val_loss: 1.6072 - val_accuracy: 0.2083\n",
      "Epoch 111/300\n",
      "93/93 [==============================] - 0s 129us/step - loss: 1.3990 - accuracy: 0.4516 - val_loss: 1.6071 - val_accuracy: 0.2083\n",
      "Epoch 112/300\n",
      "93/93 [==============================] - 0s 104us/step - loss: 1.3968 - accuracy: 0.4516 - val_loss: 1.6071 - val_accuracy: 0.2083\n",
      "Epoch 113/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.3945 - accuracy: 0.4516 - val_loss: 1.6068 - val_accuracy: 0.2083\n",
      "Epoch 114/300\n",
      "93/93 [==============================] - 0s 87us/step - loss: 1.3920 - accuracy: 0.4516 - val_loss: 1.6069 - val_accuracy: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "93/93 [==============================] - 0s 148us/step - loss: 1.3898 - accuracy: 0.4516 - val_loss: 1.6069 - val_accuracy: 0.2083\n",
      "Epoch 116/300\n",
      "93/93 [==============================] - 0s 116us/step - loss: 1.3877 - accuracy: 0.4409 - val_loss: 1.6067 - val_accuracy: 0.2083\n",
      "Epoch 117/300\n",
      "93/93 [==============================] - 0s 138us/step - loss: 1.3855 - accuracy: 0.4409 - val_loss: 1.6067 - val_accuracy: 0.2083\n",
      "Epoch 118/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.3833 - accuracy: 0.4409 - val_loss: 1.6065 - val_accuracy: 0.2083\n",
      "Epoch 119/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.3810 - accuracy: 0.4409 - val_loss: 1.6056 - val_accuracy: 0.2083\n",
      "Epoch 120/300\n",
      "93/93 [==============================] - 0s 119us/step - loss: 1.3787 - accuracy: 0.4409 - val_loss: 1.6052 - val_accuracy: 0.2083\n",
      "Epoch 121/300\n",
      "93/93 [==============================] - 0s 155us/step - loss: 1.3764 - accuracy: 0.4409 - val_loss: 1.6050 - val_accuracy: 0.2083\n",
      "Epoch 122/300\n",
      "93/93 [==============================] - 0s 177us/step - loss: 1.3743 - accuracy: 0.4409 - val_loss: 1.6042 - val_accuracy: 0.2083\n",
      "Epoch 123/300\n",
      "93/93 [==============================] - 0s 134us/step - loss: 1.3722 - accuracy: 0.4409 - val_loss: 1.6041 - val_accuracy: 0.2083\n",
      "Epoch 124/300\n",
      "93/93 [==============================] - 0s 137us/step - loss: 1.3700 - accuracy: 0.4409 - val_loss: 1.6037 - val_accuracy: 0.2083\n",
      "Epoch 125/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.3679 - accuracy: 0.4409 - val_loss: 1.6033 - val_accuracy: 0.2083\n",
      "Epoch 126/300\n",
      "93/93 [==============================] - 0s 127us/step - loss: 1.3658 - accuracy: 0.4409 - val_loss: 1.6026 - val_accuracy: 0.2500\n",
      "Epoch 127/300\n",
      "93/93 [==============================] - 0s 139us/step - loss: 1.3635 - accuracy: 0.4409 - val_loss: 1.6022 - val_accuracy: 0.2500\n",
      "Epoch 128/300\n",
      "93/93 [==============================] - 0s 118us/step - loss: 1.3612 - accuracy: 0.4409 - val_loss: 1.6017 - val_accuracy: 0.2500\n",
      "Epoch 129/300\n",
      "93/93 [==============================] - 0s 140us/step - loss: 1.3590 - accuracy: 0.4409 - val_loss: 1.6014 - val_accuracy: 0.2500\n",
      "Epoch 130/300\n",
      "93/93 [==============================] - 0s 140us/step - loss: 1.3568 - accuracy: 0.4301 - val_loss: 1.6011 - val_accuracy: 0.2500\n",
      "Epoch 131/300\n",
      "93/93 [==============================] - 0s 128us/step - loss: 1.3546 - accuracy: 0.4301 - val_loss: 1.6011 - val_accuracy: 0.2500\n",
      "Epoch 132/300\n",
      "93/93 [==============================] - 0s 150us/step - loss: 1.3524 - accuracy: 0.4301 - val_loss: 1.6006 - val_accuracy: 0.2500\n",
      "Epoch 133/300\n",
      "93/93 [==============================] - 0s 179us/step - loss: 1.3501 - accuracy: 0.4301 - val_loss: 1.6002 - val_accuracy: 0.2500\n",
      "Epoch 134/300\n",
      "93/93 [==============================] - 0s 151us/step - loss: 1.3481 - accuracy: 0.4301 - val_loss: 1.5994 - val_accuracy: 0.2500\n",
      "Epoch 135/300\n",
      "93/93 [==============================] - 0s 204us/step - loss: 1.3457 - accuracy: 0.4301 - val_loss: 1.5986 - val_accuracy: 0.2500\n",
      "Epoch 136/300\n",
      "93/93 [==============================] - 0s 155us/step - loss: 1.3434 - accuracy: 0.4301 - val_loss: 1.5980 - val_accuracy: 0.2500\n",
      "Epoch 137/300\n",
      "93/93 [==============================] - 0s 137us/step - loss: 1.3412 - accuracy: 0.4301 - val_loss: 1.5983 - val_accuracy: 0.2500\n",
      "Epoch 138/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.3391 - accuracy: 0.4301 - val_loss: 1.5983 - val_accuracy: 0.2500\n",
      "Epoch 139/300\n",
      "93/93 [==============================] - 0s 114us/step - loss: 1.3368 - accuracy: 0.4301 - val_loss: 1.5980 - val_accuracy: 0.2500\n",
      "Epoch 140/300\n",
      "93/93 [==============================] - 0s 653us/step - loss: 1.3348 - accuracy: 0.4301 - val_loss: 1.5983 - val_accuracy: 0.2500\n",
      "Epoch 141/300\n",
      "93/93 [==============================] - 0s 140us/step - loss: 1.3326 - accuracy: 0.4301 - val_loss: 1.5980 - val_accuracy: 0.2500\n",
      "Epoch 142/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.3303 - accuracy: 0.4301 - val_loss: 1.5976 - val_accuracy: 0.2500\n",
      "Epoch 143/300\n",
      "93/93 [==============================] - 0s 116us/step - loss: 1.3282 - accuracy: 0.4301 - val_loss: 1.5980 - val_accuracy: 0.2500\n",
      "Epoch 144/300\n",
      "93/93 [==============================] - 0s 110us/step - loss: 1.3258 - accuracy: 0.4301 - val_loss: 1.5977 - val_accuracy: 0.2500\n",
      "Epoch 145/300\n",
      "93/93 [==============================] - 0s 244us/step - loss: 1.3235 - accuracy: 0.4301 - val_loss: 1.5971 - val_accuracy: 0.2500\n",
      "Epoch 146/300\n",
      "93/93 [==============================] - 0s 114us/step - loss: 1.3213 - accuracy: 0.4301 - val_loss: 1.5959 - val_accuracy: 0.2500\n",
      "Epoch 147/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.3190 - accuracy: 0.4301 - val_loss: 1.5948 - val_accuracy: 0.2500\n",
      "Epoch 148/300\n",
      "93/93 [==============================] - 0s 103us/step - loss: 1.3168 - accuracy: 0.4301 - val_loss: 1.5938 - val_accuracy: 0.2500\n",
      "Epoch 149/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.3146 - accuracy: 0.4301 - val_loss: 1.5929 - val_accuracy: 0.2500\n",
      "Epoch 150/300\n",
      "93/93 [==============================] - 0s 123us/step - loss: 1.3122 - accuracy: 0.4301 - val_loss: 1.5907 - val_accuracy: 0.2500\n",
      "Epoch 151/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.3096 - accuracy: 0.4301 - val_loss: 1.5885 - val_accuracy: 0.2500\n",
      "Epoch 152/300\n",
      "93/93 [==============================] - 0s 269us/step - loss: 1.3070 - accuracy: 0.4301 - val_loss: 1.5868 - val_accuracy: 0.2500\n",
      "Epoch 153/300\n",
      "93/93 [==============================] - 0s 114us/step - loss: 1.3046 - accuracy: 0.4409 - val_loss: 1.5857 - val_accuracy: 0.2500\n",
      "Epoch 154/300\n",
      "93/93 [==============================] - 0s 119us/step - loss: 1.3019 - accuracy: 0.4301 - val_loss: 1.5834 - val_accuracy: 0.2500\n",
      "Epoch 155/300\n",
      "93/93 [==============================] - 0s 143us/step - loss: 1.2992 - accuracy: 0.4409 - val_loss: 1.5818 - val_accuracy: 0.2500\n",
      "Epoch 156/300\n",
      "93/93 [==============================] - 0s 137us/step - loss: 1.2968 - accuracy: 0.4409 - val_loss: 1.5801 - val_accuracy: 0.2500\n",
      "Epoch 157/300\n",
      "93/93 [==============================] - 0s 128us/step - loss: 1.2944 - accuracy: 0.4409 - val_loss: 1.5794 - val_accuracy: 0.2500\n",
      "Epoch 158/300\n",
      "93/93 [==============================] - 0s 336us/step - loss: 1.2923 - accuracy: 0.4409 - val_loss: 1.5786 - val_accuracy: 0.2500\n",
      "Epoch 159/300\n",
      "93/93 [==============================] - 0s 163us/step - loss: 1.2898 - accuracy: 0.4409 - val_loss: 1.5767 - val_accuracy: 0.2500\n",
      "Epoch 160/300\n",
      "93/93 [==============================] - 0s 166us/step - loss: 1.2874 - accuracy: 0.4409 - val_loss: 1.5756 - val_accuracy: 0.2500\n",
      "Epoch 161/300\n",
      "93/93 [==============================] - 0s 179us/step - loss: 1.2850 - accuracy: 0.4409 - val_loss: 1.5743 - val_accuracy: 0.2500\n",
      "Epoch 162/300\n",
      "93/93 [==============================] - 0s 135us/step - loss: 1.2825 - accuracy: 0.4409 - val_loss: 1.5732 - val_accuracy: 0.2500\n",
      "Epoch 163/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.2801 - accuracy: 0.4409 - val_loss: 1.5712 - val_accuracy: 0.2500\n",
      "Epoch 164/300\n",
      "93/93 [==============================] - 0s 144us/step - loss: 1.2776 - accuracy: 0.4409 - val_loss: 1.5696 - val_accuracy: 0.2917\n",
      "Epoch 165/300\n",
      "93/93 [==============================] - 0s 157us/step - loss: 1.2753 - accuracy: 0.4409 - val_loss: 1.5685 - val_accuracy: 0.2917\n",
      "Epoch 166/300\n",
      "93/93 [==============================] - 0s 138us/step - loss: 1.2731 - accuracy: 0.4409 - val_loss: 1.5673 - val_accuracy: 0.2917\n",
      "Epoch 167/300\n",
      "93/93 [==============================] - 0s 173us/step - loss: 1.2707 - accuracy: 0.4409 - val_loss: 1.5659 - val_accuracy: 0.2917\n",
      "Epoch 168/300\n",
      "93/93 [==============================] - 0s 132us/step - loss: 1.2684 - accuracy: 0.4409 - val_loss: 1.5651 - val_accuracy: 0.2917\n",
      "Epoch 169/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.2662 - accuracy: 0.4409 - val_loss: 1.5638 - val_accuracy: 0.2917\n",
      "Epoch 170/300\n",
      "93/93 [==============================] - 0s 705us/step - loss: 1.2639 - accuracy: 0.4409 - val_loss: 1.5628 - val_accuracy: 0.2917\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 220us/step - loss: 1.2617 - accuracy: 0.4409 - val_loss: 1.5618 - val_accuracy: 0.2917\n",
      "Epoch 172/300\n",
      "93/93 [==============================] - 0s 139us/step - loss: 1.2595 - accuracy: 0.4409 - val_loss: 1.5611 - val_accuracy: 0.2917\n",
      "Epoch 173/300\n",
      "93/93 [==============================] - 0s 101us/step - loss: 1.2573 - accuracy: 0.4409 - val_loss: 1.5597 - val_accuracy: 0.2917\n",
      "Epoch 174/300\n",
      "93/93 [==============================] - 0s 276us/step - loss: 1.2550 - accuracy: 0.4409 - val_loss: 1.5595 - val_accuracy: 0.2917\n",
      "Epoch 175/300\n",
      "93/93 [==============================] - 0s 185us/step - loss: 1.2528 - accuracy: 0.4409 - val_loss: 1.5584 - val_accuracy: 0.2917\n",
      "Epoch 176/300\n",
      "93/93 [==============================] - 0s 186us/step - loss: 1.2507 - accuracy: 0.4409 - val_loss: 1.5577 - val_accuracy: 0.2917\n",
      "Epoch 177/300\n",
      "93/93 [==============================] - 0s 180us/step - loss: 1.2484 - accuracy: 0.4516 - val_loss: 1.5568 - val_accuracy: 0.2917\n",
      "Epoch 178/300\n",
      "93/93 [==============================] - 0s 112us/step - loss: 1.2460 - accuracy: 0.4516 - val_loss: 1.5557 - val_accuracy: 0.2917\n",
      "Epoch 179/300\n",
      "93/93 [==============================] - 0s 387us/step - loss: 1.2438 - accuracy: 0.4516 - val_loss: 1.5554 - val_accuracy: 0.2917\n",
      "Epoch 180/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.2416 - accuracy: 0.4516 - val_loss: 1.5540 - val_accuracy: 0.2917\n",
      "Epoch 181/300\n",
      "93/93 [==============================] - 0s 111us/step - loss: 1.2393 - accuracy: 0.4516 - val_loss: 1.5530 - val_accuracy: 0.2917\n",
      "Epoch 182/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.2372 - accuracy: 0.4516 - val_loss: 1.5516 - val_accuracy: 0.2917\n",
      "Epoch 183/300\n",
      "93/93 [==============================] - 0s 109us/step - loss: 1.2351 - accuracy: 0.4516 - val_loss: 1.5504 - val_accuracy: 0.2917\n",
      "Epoch 184/300\n",
      "93/93 [==============================] - 0s 115us/step - loss: 1.2328 - accuracy: 0.4516 - val_loss: 1.5493 - val_accuracy: 0.2917\n",
      "Epoch 185/300\n",
      "93/93 [==============================] - 0s 630us/step - loss: 1.2306 - accuracy: 0.4516 - val_loss: 1.5483 - val_accuracy: 0.2917\n",
      "Epoch 186/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.2288 - accuracy: 0.4516 - val_loss: 1.5481 - val_accuracy: 0.2917\n",
      "Epoch 187/300\n",
      "93/93 [==============================] - 0s 190us/step - loss: 1.2264 - accuracy: 0.4516 - val_loss: 1.5471 - val_accuracy: 0.2917\n",
      "Epoch 188/300\n",
      "93/93 [==============================] - 0s 155us/step - loss: 1.2244 - accuracy: 0.4516 - val_loss: 1.5467 - val_accuracy: 0.2917\n",
      "Epoch 189/300\n",
      "93/93 [==============================] - 0s 635us/step - loss: 1.2225 - accuracy: 0.4516 - val_loss: 1.5467 - val_accuracy: 0.2917\n",
      "Epoch 190/300\n",
      "93/93 [==============================] - 0s 535us/step - loss: 1.2205 - accuracy: 0.4516 - val_loss: 1.5462 - val_accuracy: 0.2917\n",
      "Epoch 191/300\n",
      "93/93 [==============================] - 0s 104us/step - loss: 1.2185 - accuracy: 0.4516 - val_loss: 1.5456 - val_accuracy: 0.2917\n",
      "Epoch 192/300\n",
      "93/93 [==============================] - 0s 179us/step - loss: 1.2166 - accuracy: 0.4516 - val_loss: 1.5453 - val_accuracy: 0.2917\n",
      "Epoch 193/300\n",
      "93/93 [==============================] - 0s 138us/step - loss: 1.2145 - accuracy: 0.4516 - val_loss: 1.5449 - val_accuracy: 0.2917\n",
      "Epoch 194/300\n",
      "93/93 [==============================] - 0s 120us/step - loss: 1.2126 - accuracy: 0.4516 - val_loss: 1.5443 - val_accuracy: 0.2917\n",
      "Epoch 195/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.2107 - accuracy: 0.4516 - val_loss: 1.5438 - val_accuracy: 0.2917\n",
      "Epoch 196/300\n",
      "93/93 [==============================] - 0s 131us/step - loss: 1.2090 - accuracy: 0.4516 - val_loss: 1.5430 - val_accuracy: 0.2917\n",
      "Epoch 197/300\n",
      "93/93 [==============================] - 0s 127us/step - loss: 1.2069 - accuracy: 0.4516 - val_loss: 1.5419 - val_accuracy: 0.2917\n",
      "Epoch 198/300\n",
      "93/93 [==============================] - 0s 150us/step - loss: 1.2049 - accuracy: 0.4516 - val_loss: 1.5415 - val_accuracy: 0.2917\n",
      "Epoch 199/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.2027 - accuracy: 0.4516 - val_loss: 1.5410 - val_accuracy: 0.2917\n",
      "Epoch 200/300\n",
      "93/93 [==============================] - 0s 462us/step - loss: 1.2011 - accuracy: 0.4516 - val_loss: 1.5409 - val_accuracy: 0.2917\n",
      "Epoch 201/300\n",
      "93/93 [==============================] - 0s 129us/step - loss: 1.1991 - accuracy: 0.4516 - val_loss: 1.5404 - val_accuracy: 0.2917\n",
      "Epoch 202/300\n",
      "93/93 [==============================] - 0s 133us/step - loss: 1.1970 - accuracy: 0.4516 - val_loss: 1.5399 - val_accuracy: 0.2917\n",
      "Epoch 203/300\n",
      "93/93 [==============================] - 0s 149us/step - loss: 1.1951 - accuracy: 0.4516 - val_loss: 1.5396 - val_accuracy: 0.2917\n",
      "Epoch 204/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.1934 - accuracy: 0.4409 - val_loss: 1.5400 - val_accuracy: 0.2917\n",
      "Epoch 205/300\n",
      "93/93 [==============================] - 0s 131us/step - loss: 1.1914 - accuracy: 0.4409 - val_loss: 1.5397 - val_accuracy: 0.2917\n",
      "Epoch 206/300\n",
      "93/93 [==============================] - 0s 183us/step - loss: 1.1896 - accuracy: 0.4409 - val_loss: 1.5390 - val_accuracy: 0.2917\n",
      "Epoch 207/300\n",
      "93/93 [==============================] - 0s 130us/step - loss: 1.1879 - accuracy: 0.4409 - val_loss: 1.5385 - val_accuracy: 0.2917\n",
      "Epoch 208/300\n",
      "93/93 [==============================] - 0s 135us/step - loss: 1.1858 - accuracy: 0.4409 - val_loss: 1.5385 - val_accuracy: 0.2917\n",
      "Epoch 209/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.1840 - accuracy: 0.4409 - val_loss: 1.5380 - val_accuracy: 0.2917\n",
      "Epoch 210/300\n",
      "93/93 [==============================] - 0s 152us/step - loss: 1.1823 - accuracy: 0.4409 - val_loss: 1.5371 - val_accuracy: 0.2917\n",
      "Epoch 211/300\n",
      "93/93 [==============================] - 0s 123us/step - loss: 1.1807 - accuracy: 0.4516 - val_loss: 1.5363 - val_accuracy: 0.2917\n",
      "Epoch 212/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.1783 - accuracy: 0.4516 - val_loss: 1.5359 - val_accuracy: 0.3333\n",
      "Epoch 213/300\n",
      "93/93 [==============================] - 0s 150us/step - loss: 1.1765 - accuracy: 0.4624 - val_loss: 1.5359 - val_accuracy: 0.3333\n",
      "Epoch 214/300\n",
      "93/93 [==============================] - 0s 391us/step - loss: 1.1747 - accuracy: 0.4731 - val_loss: 1.5360 - val_accuracy: 0.3333\n",
      "Epoch 215/300\n",
      "93/93 [==============================] - 0s 392us/step - loss: 1.1727 - accuracy: 0.4946 - val_loss: 1.5361 - val_accuracy: 0.3333\n",
      "Epoch 216/300\n",
      "93/93 [==============================] - 0s 381us/step - loss: 1.1709 - accuracy: 0.5054 - val_loss: 1.5357 - val_accuracy: 0.3333\n",
      "Epoch 217/300\n",
      "93/93 [==============================] - 0s 365us/step - loss: 1.1689 - accuracy: 0.5054 - val_loss: 1.5355 - val_accuracy: 0.3333\n",
      "Epoch 218/300\n",
      "93/93 [==============================] - 0s 417us/step - loss: 1.1672 - accuracy: 0.5054 - val_loss: 1.5348 - val_accuracy: 0.3333\n",
      "Epoch 219/300\n",
      "93/93 [==============================] - 0s 231us/step - loss: 1.1654 - accuracy: 0.5054 - val_loss: 1.5354 - val_accuracy: 0.3333\n",
      "Epoch 220/300\n",
      "93/93 [==============================] - 0s 271us/step - loss: 1.1635 - accuracy: 0.5054 - val_loss: 1.5354 - val_accuracy: 0.3750\n",
      "Epoch 221/300\n",
      "93/93 [==============================] - 0s 100us/step - loss: 1.1619 - accuracy: 0.5054 - val_loss: 1.5351 - val_accuracy: 0.3750\n",
      "Epoch 222/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.1601 - accuracy: 0.5161 - val_loss: 1.5358 - val_accuracy: 0.3750\n",
      "Epoch 223/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.1583 - accuracy: 0.5161 - val_loss: 1.5358 - val_accuracy: 0.3750\n",
      "Epoch 224/300\n",
      "93/93 [==============================] - 0s 166us/step - loss: 1.1567 - accuracy: 0.5161 - val_loss: 1.5354 - val_accuracy: 0.3750\n",
      "Epoch 225/300\n",
      "93/93 [==============================] - 0s 143us/step - loss: 1.1549 - accuracy: 0.5269 - val_loss: 1.5351 - val_accuracy: 0.3750\n",
      "Epoch 226/300\n",
      "93/93 [==============================] - 0s 169us/step - loss: 1.1532 - accuracy: 0.5269 - val_loss: 1.5344 - val_accuracy: 0.3750\n",
      "Epoch 227/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 96us/step - loss: 1.1516 - accuracy: 0.5269 - val_loss: 1.5341 - val_accuracy: 0.3750\n",
      "Epoch 228/300\n",
      "93/93 [==============================] - 0s 165us/step - loss: 1.1498 - accuracy: 0.5269 - val_loss: 1.5345 - val_accuracy: 0.3750\n",
      "Epoch 229/300\n",
      "93/93 [==============================] - 0s 182us/step - loss: 1.1482 - accuracy: 0.5269 - val_loss: 1.5353 - val_accuracy: 0.3750\n",
      "Epoch 230/300\n",
      "93/93 [==============================] - 0s 209us/step - loss: 1.1467 - accuracy: 0.5269 - val_loss: 1.5347 - val_accuracy: 0.3750\n",
      "Epoch 231/300\n",
      "93/93 [==============================] - 0s 315us/step - loss: 1.1452 - accuracy: 0.5269 - val_loss: 1.5350 - val_accuracy: 0.3750\n",
      "Epoch 232/300\n",
      "93/93 [==============================] - 0s 110us/step - loss: 1.1433 - accuracy: 0.5376 - val_loss: 1.5350 - val_accuracy: 0.3750\n",
      "Epoch 233/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.1416 - accuracy: 0.5376 - val_loss: 1.5347 - val_accuracy: 0.3750\n",
      "Epoch 234/300\n",
      "93/93 [==============================] - 0s 221us/step - loss: 1.1401 - accuracy: 0.5376 - val_loss: 1.5348 - val_accuracy: 0.3750\n",
      "Epoch 235/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.1388 - accuracy: 0.5376 - val_loss: 1.5341 - val_accuracy: 0.3750\n",
      "Epoch 236/300\n",
      "93/93 [==============================] - 0s 116us/step - loss: 1.1367 - accuracy: 0.5376 - val_loss: 1.5342 - val_accuracy: 0.3750\n",
      "Epoch 237/300\n",
      "93/93 [==============================] - 0s 203us/step - loss: 1.1352 - accuracy: 0.5269 - val_loss: 1.5340 - val_accuracy: 0.3750\n",
      "Epoch 238/300\n",
      "93/93 [==============================] - 0s 697us/step - loss: 1.1335 - accuracy: 0.5269 - val_loss: 1.5337 - val_accuracy: 0.3750\n",
      "Epoch 239/300\n",
      "93/93 [==============================] - 0s 176us/step - loss: 1.1321 - accuracy: 0.5269 - val_loss: 1.5329 - val_accuracy: 0.3750\n",
      "Epoch 240/300\n",
      "93/93 [==============================] - 0s 133us/step - loss: 1.1306 - accuracy: 0.5269 - val_loss: 1.5327 - val_accuracy: 0.3750\n",
      "Epoch 241/300\n",
      "93/93 [==============================] - 0s 257us/step - loss: 1.1293 - accuracy: 0.5269 - val_loss: 1.5318 - val_accuracy: 0.3750\n",
      "Epoch 242/300\n",
      "93/93 [==============================] - 0s 135us/step - loss: 1.1272 - accuracy: 0.5484 - val_loss: 1.5316 - val_accuracy: 0.3750\n",
      "Epoch 243/300\n",
      "93/93 [==============================] - 0s 135us/step - loss: 1.1256 - accuracy: 0.5484 - val_loss: 1.5313 - val_accuracy: 0.3750\n",
      "Epoch 244/300\n",
      "93/93 [==============================] - 0s 109us/step - loss: 1.1243 - accuracy: 0.5484 - val_loss: 1.5312 - val_accuracy: 0.3750\n",
      "Epoch 245/300\n",
      "93/93 [==============================] - 0s 121us/step - loss: 1.1226 - accuracy: 0.5484 - val_loss: 1.5310 - val_accuracy: 0.3750\n",
      "Epoch 246/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.1211 - accuracy: 0.5591 - val_loss: 1.5316 - val_accuracy: 0.3750\n",
      "Epoch 247/300\n",
      "93/93 [==============================] - 0s 121us/step - loss: 1.1196 - accuracy: 0.5484 - val_loss: 1.5315 - val_accuracy: 0.3750\n",
      "Epoch 248/300\n",
      "93/93 [==============================] - 0s 149us/step - loss: 1.1180 - accuracy: 0.5591 - val_loss: 1.5315 - val_accuracy: 0.3750\n",
      "Epoch 249/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.1167 - accuracy: 0.5484 - val_loss: 1.5316 - val_accuracy: 0.3750\n",
      "Epoch 250/300\n",
      "93/93 [==============================] - 0s 106us/step - loss: 1.1153 - accuracy: 0.5484 - val_loss: 1.5304 - val_accuracy: 0.3750\n",
      "Epoch 251/300\n",
      "93/93 [==============================] - 0s 146us/step - loss: 1.1137 - accuracy: 0.5376 - val_loss: 1.5302 - val_accuracy: 0.3750\n",
      "Epoch 252/300\n",
      "93/93 [==============================] - 0s 120us/step - loss: 1.1121 - accuracy: 0.5484 - val_loss: 1.5309 - val_accuracy: 0.3750\n",
      "Epoch 253/300\n",
      "93/93 [==============================] - 0s 119us/step - loss: 1.1106 - accuracy: 0.5591 - val_loss: 1.5310 - val_accuracy: 0.4167\n",
      "Epoch 254/300\n",
      "93/93 [==============================] - 0s 107us/step - loss: 1.1091 - accuracy: 0.5376 - val_loss: 1.5306 - val_accuracy: 0.4167\n",
      "Epoch 255/300\n",
      "93/93 [==============================] - 0s 168us/step - loss: 1.1076 - accuracy: 0.5484 - val_loss: 1.5305 - val_accuracy: 0.4167\n",
      "Epoch 256/300\n",
      "93/93 [==============================] - 0s 121us/step - loss: 1.1068 - accuracy: 0.5484 - val_loss: 1.5305 - val_accuracy: 0.4167\n",
      "Epoch 257/300\n",
      "93/93 [==============================] - 0s 111us/step - loss: 1.1050 - accuracy: 0.5699 - val_loss: 1.5306 - val_accuracy: 0.4167\n",
      "Epoch 258/300\n",
      "93/93 [==============================] - 0s 258us/step - loss: 1.1034 - accuracy: 0.5699 - val_loss: 1.5305 - val_accuracy: 0.4167\n",
      "Epoch 259/300\n",
      "93/93 [==============================] - 0s 179us/step - loss: 1.1022 - accuracy: 0.5699 - val_loss: 1.5311 - val_accuracy: 0.4167\n",
      "Epoch 260/300\n",
      "93/93 [==============================] - 0s 155us/step - loss: 1.1009 - accuracy: 0.5699 - val_loss: 1.5310 - val_accuracy: 0.4167\n",
      "Epoch 261/300\n",
      "93/93 [==============================] - 0s 120us/step - loss: 1.0994 - accuracy: 0.5699 - val_loss: 1.5316 - val_accuracy: 0.4167\n",
      "Epoch 262/300\n",
      "93/93 [==============================] - 0s 184us/step - loss: 1.0980 - accuracy: 0.5699 - val_loss: 1.5319 - val_accuracy: 0.4167\n",
      "Epoch 263/300\n",
      "93/93 [==============================] - 0s 152us/step - loss: 1.0969 - accuracy: 0.5699 - val_loss: 1.5319 - val_accuracy: 0.4167\n",
      "Epoch 264/300\n",
      "93/93 [==============================] - 0s 567us/step - loss: 1.0951 - accuracy: 0.5699 - val_loss: 1.5314 - val_accuracy: 0.4167\n",
      "Epoch 265/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.0938 - accuracy: 0.5699 - val_loss: 1.5314 - val_accuracy: 0.4167\n",
      "Epoch 266/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.0927 - accuracy: 0.5699 - val_loss: 1.5316 - val_accuracy: 0.3750\n",
      "Epoch 267/300\n",
      "93/93 [==============================] - 0s 146us/step - loss: 1.0911 - accuracy: 0.5699 - val_loss: 1.5316 - val_accuracy: 0.3750\n",
      "Epoch 268/300\n",
      "93/93 [==============================] - 0s 191us/step - loss: 1.0904 - accuracy: 0.5699 - val_loss: 1.5318 - val_accuracy: 0.3750\n",
      "Epoch 269/300\n",
      "93/93 [==============================] - 0s 110us/step - loss: 1.0889 - accuracy: 0.5699 - val_loss: 1.5321 - val_accuracy: 0.3750\n",
      "Epoch 270/300\n",
      "93/93 [==============================] - 0s 181us/step - loss: 1.0871 - accuracy: 0.5699 - val_loss: 1.5320 - val_accuracy: 0.3750\n",
      "Epoch 271/300\n",
      "93/93 [==============================] - 0s 149us/step - loss: 1.0860 - accuracy: 0.5699 - val_loss: 1.5327 - val_accuracy: 0.3750\n",
      "Epoch 272/300\n",
      "93/93 [==============================] - 0s 136us/step - loss: 1.0846 - accuracy: 0.5699 - val_loss: 1.5328 - val_accuracy: 0.3750\n",
      "Epoch 273/300\n",
      "93/93 [==============================] - 0s 171us/step - loss: 1.0834 - accuracy: 0.5699 - val_loss: 1.5325 - val_accuracy: 0.3750\n",
      "Epoch 274/300\n",
      "93/93 [==============================] - 0s 106us/step - loss: 1.0819 - accuracy: 0.5699 - val_loss: 1.5318 - val_accuracy: 0.4167\n",
      "Epoch 275/300\n",
      "93/93 [==============================] - 0s 247us/step - loss: 1.0805 - accuracy: 0.5699 - val_loss: 1.5315 - val_accuracy: 0.4167\n",
      "Epoch 276/300\n",
      "93/93 [==============================] - 0s 290us/step - loss: 1.0788 - accuracy: 0.5699 - val_loss: 1.5323 - val_accuracy: 0.4167\n",
      "Epoch 277/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.0777 - accuracy: 0.5806 - val_loss: 1.5327 - val_accuracy: 0.4167\n",
      "Epoch 278/300\n",
      "93/93 [==============================] - 0s 161us/step - loss: 1.0761 - accuracy: 0.5806 - val_loss: 1.5324 - val_accuracy: 0.4167\n",
      "Epoch 279/300\n",
      "93/93 [==============================] - 0s 147us/step - loss: 1.0750 - accuracy: 0.5806 - val_loss: 1.5319 - val_accuracy: 0.4167\n",
      "Epoch 280/300\n",
      "93/93 [==============================] - 0s 256us/step - loss: 1.0736 - accuracy: 0.5806 - val_loss: 1.5330 - val_accuracy: 0.4167\n",
      "Epoch 281/300\n",
      "93/93 [==============================] - 0s 208us/step - loss: 1.0720 - accuracy: 0.5699 - val_loss: 1.5328 - val_accuracy: 0.4167\n",
      "Epoch 282/300\n",
      "93/93 [==============================] - 0s 227us/step - loss: 1.0713 - accuracy: 0.5699 - val_loss: 1.5332 - val_accuracy: 0.4167\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 0s 136us/step - loss: 1.0693 - accuracy: 0.5699 - val_loss: 1.5333 - val_accuracy: 0.4167\n",
      "Epoch 284/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.0679 - accuracy: 0.5806 - val_loss: 1.5338 - val_accuracy: 0.4167\n",
      "Epoch 285/300\n",
      "93/93 [==============================] - 0s 142us/step - loss: 1.0665 - accuracy: 0.5806 - val_loss: 1.5341 - val_accuracy: 0.4167\n",
      "Epoch 286/300\n",
      "93/93 [==============================] - 0s 604us/step - loss: 1.0653 - accuracy: 0.5806 - val_loss: 1.5339 - val_accuracy: 0.4167\n",
      "Epoch 287/300\n",
      "93/93 [==============================] - 0s 112us/step - loss: 1.0640 - accuracy: 0.5806 - val_loss: 1.5350 - val_accuracy: 0.4167\n",
      "Epoch 288/300\n",
      "93/93 [==============================] - 0s 158us/step - loss: 1.0625 - accuracy: 0.5806 - val_loss: 1.5350 - val_accuracy: 0.4167\n",
      "Epoch 289/300\n",
      "93/93 [==============================] - 0s 94us/step - loss: 1.0611 - accuracy: 0.5914 - val_loss: 1.5346 - val_accuracy: 0.4167\n",
      "Epoch 290/300\n",
      "93/93 [==============================] - 0s 124us/step - loss: 1.0598 - accuracy: 0.5914 - val_loss: 1.5354 - val_accuracy: 0.4167\n",
      "Epoch 291/300\n",
      "93/93 [==============================] - 0s 209us/step - loss: 1.0583 - accuracy: 0.5914 - val_loss: 1.5353 - val_accuracy: 0.4167\n",
      "Epoch 292/300\n",
      "93/93 [==============================] - 0s 105us/step - loss: 1.0572 - accuracy: 0.5914 - val_loss: 1.5355 - val_accuracy: 0.4167\n",
      "Epoch 293/300\n",
      "93/93 [==============================] - 0s 218us/step - loss: 1.0558 - accuracy: 0.5914 - val_loss: 1.5360 - val_accuracy: 0.3750\n",
      "Epoch 294/300\n",
      "93/93 [==============================] - 0s 125us/step - loss: 1.0544 - accuracy: 0.5914 - val_loss: 1.5366 - val_accuracy: 0.3750\n",
      "Epoch 295/300\n",
      "93/93 [==============================] - 0s 152us/step - loss: 1.0533 - accuracy: 0.5914 - val_loss: 1.5364 - val_accuracy: 0.3750\n",
      "Epoch 296/300\n",
      "93/93 [==============================] - 0s 145us/step - loss: 1.0513 - accuracy: 0.5914 - val_loss: 1.5366 - val_accuracy: 0.3750\n",
      "Epoch 297/300\n",
      "93/93 [==============================] - 0s 140us/step - loss: 1.0503 - accuracy: 0.5914 - val_loss: 1.5364 - val_accuracy: 0.3750\n",
      "Epoch 298/300\n",
      "93/93 [==============================] - 0s 126us/step - loss: 1.0485 - accuracy: 0.5914 - val_loss: 1.5363 - val_accuracy: 0.3750\n",
      "Epoch 299/300\n",
      "93/93 [==============================] - 0s 117us/step - loss: 1.0471 - accuracy: 0.5914 - val_loss: 1.5369 - val_accuracy: 0.3750\n",
      "Epoch 300/300\n",
      "93/93 [==============================] - 0s 113us/step - loss: 1.0458 - accuracy: 0.5914 - val_loss: 1.5379 - val_accuracy: 0.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x146c93fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction model: Neural network \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=11, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation='softmax')) \n",
    "                                            \n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# Fitting the NN to the Training set\n",
    "model.fit(prediction_input_preprocessor.transform(X_train), pd.get_dummies(y_train), \n",
    "               batch_size = 60, \n",
    "               epochs = 300, validation_split=0.2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 4 1 1 1 1 4 1 1 3 2 3 1 4 4 4 1 4 3 3 3 1 2 1 1 0 4 1 4 3 4 2 4 4\n",
      " 4 1]\n",
      "['High', 'High', 'High', 'High', 'Very Low', 'High', 'High', 'High', 'High', 'Very Low', 'High', 'High', 'Very High', 'Low', 'Very High', 'High', 'Very Low', 'Very Low', 'Very Low', 'High', 'Very Low', 'Very High', 'Very High', 'Very High', 'High', 'Low', 'High', 'High', 'Average', 'Very Low', 'High', 'Very Low', 'Very High', 'Very Low', 'Low', 'Very Low', 'Very Low', 'Very Low', 'High']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_classes(prediction_input_preprocessor.transform(X_test)))\n",
    "\n",
    "\n",
    "prediction_index=model.predict_classes(prediction_input_preprocessor.transform(X_test))\n",
    "\n",
    "#Now lets run some code to get keras to return the label rather than the index...\n",
    "\n",
    "# get labels from one hot encoded y_train data\n",
    "labels=pd.get_dummies(y_train).columns\n",
    "\n",
    "# Function to use to return label from column index location\n",
    "def index_to_label(labels,index_n): \n",
    "    return labels[index_n]\n",
    "    \n",
    "# Example: return label at predicted index location 1\n",
    "index_to_label(labels,1)\n",
    "\n",
    "# Iterate through all predicted indices using map method\n",
    "\n",
    "predicted_labels=list(map(lambda x: labels[x], prediction_index))\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.399089</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.452778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
       "0  0.435897  0.399089   0.447059  0.452778    0     0    0   0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating Keras Model\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "\n",
    "def model_eval_metrics(y_true, y_pred,classification=\"TRUE\"):\n",
    "     if classification==\"TRUE\":\n",
    "        accuracy_eval = accuracy_score(y_true, y_pred)\n",
    "        f1_score_eval = f1_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        precision_eval = precision_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        recall_eval = recall_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
    "        mse_eval = 0\n",
    "        rmse_eval = 0\n",
    "        mae_eval = 0\n",
    "        r2_eval = 0\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     else:\n",
    "        accuracy_eval = 0\n",
    "        f1_score_eval = 0\n",
    "        precision_eval = 0\n",
    "        recall_eval = 0\n",
    "        mse_eval = mean_squared_error(y_true, y_pred)\n",
    "        rmse_eval = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        mae_eval = mean_absolute_error(y_true, y_pred)\n",
    "        r2_eval = r2_score(y_true, y_pred)\n",
    "        metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
    "        finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
    "     return finalmetricdata\n",
    "\n",
    "model_eval_metrics( y_test,predicted_labels,classification=\"TRUE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the best performing model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true\n",
      "  Using cached https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true\n",
      "Requirement already satisfied (use --upgrade to upgrade): aimodelshare==0.0.2 from https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true in ./anaconda3/lib/python3.7/site-packages\n",
      "Building wheels for collected packages: aimodelshare\n",
      "  Building wheel for aimodelshare (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/raquelsenior/Library/Caches/pip/wheels/31/8d/ac/09cb6ef7374ec79e02843c347195e5478144006b11def6799a\n",
      "Successfully built aimodelshare\n"
     ]
    }
   ],
   "source": [
    "#install aimodelshare library\n",
    "! pip install https://github.com/mikedparrott/aimodelshare/blob/master/aimodelshare-0.0.2.tar.gz?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Loading AWS keys necessary to submit model.  Loading to object, so we don't print them out in our notebook\n",
    "\n",
    "aws_key_password_region = pickle.load( open( \"/Users/raquelsenior/Desktop/QMSS/Adv_ML/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiurl=\"https://btuvanmi55.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "username = \"password\"\n",
    "password = \"username\"\n",
    "\n",
    "region='us-east-1'\n",
    "model_filepath=\"mymodel.onnx\"   \n",
    "preprocessor_filepath=\"preprocessor.pkl\"\n",
    "preprocessor=\"TRUE\"\n",
    "\n",
    "trainingdata=X_train\n",
    "\n",
    "# Set aws keys for this project (these keys give you access to collaborate on a single project)\n",
    "\n",
    "#Importing from object that stores keys so we do not print out keys for others to see.\n",
    "\n",
    "aws_key_password_region = pickle.load( open(\"/Users/raquelsenior/Desktop/QMSS/Adv_ML/worldhappiness_modelsubmission_keys.pkl\", \"rb\" ) )\n",
    "\n",
    "aws_key=aws_key_password_region[0]\n",
    "aws_password=aws_key_password_region[1]\n",
    "region=aws_key_password_region[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiurl=\"https://btuvanmi55.execute-api.us-east-1.amazonaws.com/prod/m\"\n",
    "username = \"username\"\n",
    "password = \"password\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEADERBOARD RANKINGS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mae</th>\n",
       "      <th>r2</th>\n",
       "      <th>username</th>\n",
       "      <th>model_version</th>\n",
       "      <th>avg_ranking_classification</th>\n",
       "      <th>avg_ranking_regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>85</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>0.719444</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>70</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675975</td>\n",
       "      <td>0.754286</td>\n",
       "      <td>0.700952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>69</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.700397</td>\n",
       "      <td>0.702778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>62</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.642381</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.682273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>83</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.646886</td>\n",
       "      <td>0.738333</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>68</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.639160</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>82</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.639160</td>\n",
       "      <td>0.660476</td>\n",
       "      <td>0.700455</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>81</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.620793</td>\n",
       "      <td>0.634394</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>79</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.620793</td>\n",
       "      <td>0.634394</td>\n",
       "      <td>0.658636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>80</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.620742</td>\n",
       "      <td>0.656190</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XU</td>\n",
       "      <td>94</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.594805</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.640952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>67</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.593389</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.623968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XU</td>\n",
       "      <td>92</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.566499</td>\n",
       "      <td>0.647863</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alpaca</td>\n",
       "      <td>118</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.560856</td>\n",
       "      <td>0.633131</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>120</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.564118</td>\n",
       "      <td>0.617460</td>\n",
       "      <td>0.568889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>122</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.566545</td>\n",
       "      <td>0.591111</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>95</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username1</td>\n",
       "      <td>110</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username1</td>\n",
       "      <td>112</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username1</td>\n",
       "      <td>110</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.522434</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username1</td>\n",
       "      <td>111</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.575079</td>\n",
       "      <td>0.612424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jk3971</td>\n",
       "      <td>121</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.535233</td>\n",
       "      <td>0.612308</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>104</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.546569</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>84</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.532886</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>114</td>\n",
       "      <td>17.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.543627</td>\n",
       "      <td>0.580123</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>86</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.508060</td>\n",
       "      <td>0.625909</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>19</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.517494</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.530556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>96</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.516805</td>\n",
       "      <td>0.594383</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Taketo</td>\n",
       "      <td>91</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.504464</td>\n",
       "      <td>0.604242</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>37</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>12</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yihui_Wang</td>\n",
       "      <td>38</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>10</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>jaeham</td>\n",
       "      <td>35</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SUN-Wenjun</td>\n",
       "      <td>28</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>44</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>53</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paarth_Malkan</td>\n",
       "      <td>42</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AlisaAi</td>\n",
       "      <td>39</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>XU</td>\n",
       "      <td>32</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dhoward97</td>\n",
       "      <td>61</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>29</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>seanmcalevey</td>\n",
       "      <td>60</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3scman</td>\n",
       "      <td>33</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ccabelloe</td>\n",
       "      <td>36</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>9</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nayyer-Qureshi</td>\n",
       "      <td>28</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>7</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>31</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.397653</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alpaca</td>\n",
       "      <td>89</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.388293</td>\n",
       "      <td>0.474697</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alpaca</td>\n",
       "      <td>90</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.373647</td>\n",
       "      <td>0.448333</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>113</td>\n",
       "      <td>47.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.343861</td>\n",
       "      <td>0.348889</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>zivzach</td>\n",
       "      <td>50</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.348535</td>\n",
       "      <td>0.421667</td>\n",
       "      <td>0.338889</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>123</td>\n",
       "      <td>49.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.303896</td>\n",
       "      <td>0.340260</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>abhay_07</td>\n",
       "      <td>18</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>2</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>3</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.337698</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>username2</td>\n",
       "      <td>6</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.336015</td>\n",
       "      <td>0.354048</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>101</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.336015</td>\n",
       "      <td>0.354048</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>raquel904</td>\n",
       "      <td>102</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  f1_score  precision    recall  mse  rmse  mae  r2  \\\n",
       "7    0.717949  0.717857   0.717857  0.727778    0     0    0   0   \n",
       "8    0.717949  0.713796   0.719444  0.725000    0     0    0   0   \n",
       "9    0.666667  0.675975   0.754286  0.700952    0     0    0   0   \n",
       "10   0.692308  0.693333   0.700397  0.702778    0     0    0   0   \n",
       "11   0.641026  0.642381   0.743590  0.682273    0     0    0   0   \n",
       "12   0.641026  0.646886   0.738333  0.680952    0     0    0   0   \n",
       "14   0.641026  0.639160   0.660476  0.700455    0     0    0   0   \n",
       "13   0.641026  0.639160   0.660476  0.700455    0     0    0   0   \n",
       "16   0.615385  0.620793   0.634394  0.658636    0     0    0   0   \n",
       "15   0.615385  0.620793   0.634394  0.658636    0     0    0   0   \n",
       "18   0.615385  0.620742   0.656190  0.643968    0     0    0   0   \n",
       "17   0.589744  0.594805   0.714286  0.640952    0     0    0   0   \n",
       "19   0.589744  0.593389   0.625000  0.623968    0     0    0   0   \n",
       "121  0.564103  0.566499   0.647863  0.588889    0     0    0   0   \n",
       "3    0.564103  0.560856   0.633131  0.580556    0     0    0   0   \n",
       "123  0.589744  0.564118   0.617460  0.568889    0     0    0   0   \n",
       "20   0.564103  0.566545   0.591111  0.586111    0     0    0   0   \n",
       "117  0.564103  0.522434   0.617647  0.550000    0     0    0   0   \n",
       "119  0.564103  0.522434   0.617647  0.550000    0     0    0   0   \n",
       "116  0.564103  0.522434   0.617647  0.550000    0     0    0   0   \n",
       "118  0.564103  0.522434   0.617647  0.550000    0     0    0   0   \n",
       "125  0.538462  0.548333   0.575079  0.612424    0     0    0   0   \n",
       "21   0.538462  0.535233   0.612308  0.544444    0     0    0   0   \n",
       "22   0.538462  0.546569   0.590909  0.558333    0     0    0   0   \n",
       "120  0.538462  0.532886   0.600000  0.555556    0     0    0   0   \n",
       "24   0.538462  0.543627   0.580123  0.569444    0     0    0   0   \n",
       "23   0.512821  0.508060   0.625909  0.544444    0     0    0   0   \n",
       "25   0.512821  0.517494   0.604762  0.530556    0     0    0   0   \n",
       "26   0.512821  0.516805   0.594383  0.533333    0     0    0   0   \n",
       "27   0.512821  0.504464   0.604242  0.544444    0     0    0   0   \n",
       "..        ...       ...        ...       ...  ...   ...  ...  ..   \n",
       "102  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "101  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "104  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "99   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "90   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "91   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "92   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "87   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "100  0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "86   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "85   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "89   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "84   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "93   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "94   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "95   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "96   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "97   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "98   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "88   0.384615  0.397653   0.482937  0.383333    0     0    0   0   \n",
       "108  0.384615  0.388293   0.474697  0.386111    0     0    0   0   \n",
       "2    0.358974  0.373647   0.448333  0.361111    0     0    0   0   \n",
       "109  0.384615  0.343861   0.348889  0.422222    0     0    0   0   \n",
       "127  0.333333  0.348535   0.421667  0.338889    0     0    0   0   \n",
       "110  0.384615  0.303896   0.340260  0.425000    0     0    0   0   \n",
       "113  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "112  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "111  0.333333  0.337698   0.385556  0.322222    0     0    0   0   \n",
       "115  0.333333  0.336015   0.354048  0.325000    0     0    0   0   \n",
       "114  0.333333  0.336015   0.354048  0.325000    0     0    0   0   \n",
       "\n",
       "           username  model_version  avg_ranking_classification  \\\n",
       "7            3scman             85                    2.333333   \n",
       "8            3scman             70                    2.333333   \n",
       "9         dhoward97             69                    2.666667   \n",
       "10           3scman             62                    4.000000   \n",
       "11       SUN-Wenjun             83                    4.000000   \n",
       "12        dhoward97             68                    4.000000   \n",
       "14       SUN-Wenjun             82                    6.333333   \n",
       "13       SUN-Wenjun             81                    6.333333   \n",
       "16       SUN-Wenjun             79                    8.000000   \n",
       "15       SUN-Wenjun             80                    8.000000   \n",
       "18               XU             94                    7.666667   \n",
       "17        dhoward97             67                    7.333333   \n",
       "19               XU             92                   10.333333   \n",
       "121          Alpaca            118                   10.333333   \n",
       "3            jaeham            120                   11.666667   \n",
       "123         zivzach            122                   12.333333   \n",
       "20           jaeham             95                   15.000000   \n",
       "117       username1            110                   15.000000   \n",
       "119       username1            112                   15.000000   \n",
       "116       username1            110                   15.000000   \n",
       "118       username1            111                   15.000000   \n",
       "125          jk3971            121                   18.333333   \n",
       "21           jaeham            104                   15.666667   \n",
       "22          zivzach             84                   17.666667   \n",
       "120          Taketo            114                   17.333333   \n",
       "24          zivzach             86                   18.666667   \n",
       "23       Yihui_Wang             19                   17.666667   \n",
       "25           Taketo             96                   18.000000   \n",
       "26           Taketo             91                   19.666667   \n",
       "27    Paarth_Malkan             37                   20.333333   \n",
       "..              ...            ...                         ...   \n",
       "102       username2             12                   45.000000   \n",
       "101      Yihui_Wang             38                   45.000000   \n",
       "104       username2             10                   45.000000   \n",
       "99           jaeham             35                   45.000000   \n",
       "90       SUN-Wenjun             28                   45.000000   \n",
       "91    Paarth_Malkan             44                   45.000000   \n",
       "92    Paarth_Malkan             53                   45.000000   \n",
       "87    Paarth_Malkan             42                   45.000000   \n",
       "100         AlisaAi             39                   45.000000   \n",
       "86               XU             32                   45.000000   \n",
       "85        dhoward97             61                   45.000000   \n",
       "89     seanmcalevey             29                   45.000000   \n",
       "84     seanmcalevey             60                   45.000000   \n",
       "93           3scman             33                   45.000000   \n",
       "94        ccabelloe             36                   45.000000   \n",
       "95        username2              9                   45.000000   \n",
       "96   Nayyer-Qureshi             28                   45.000000   \n",
       "97        username2              7                   45.000000   \n",
       "98         abhay_07             31                   45.000000   \n",
       "88           Alpaca             89                   45.000000   \n",
       "108          Alpaca             90                   46.000000   \n",
       "2         raquel904            113                   47.666667   \n",
       "109         zivzach             50                   50.333333   \n",
       "127       raquel904            123                   49.666667   \n",
       "110        abhay_07             18                   51.666667   \n",
       "113       username2              2                   51.000000   \n",
       "112       username2              3                   51.000000   \n",
       "111       username2              6                   51.000000   \n",
       "115       raquel904            101                   51.666667   \n",
       "114       raquel904            102                   51.666667   \n",
       "\n",
       "     avg_ranking_regression  \n",
       "7                       1.0  \n",
       "8                       1.0  \n",
       "9                       1.0  \n",
       "10                      1.0  \n",
       "11                      1.0  \n",
       "12                      1.0  \n",
       "14                      1.0  \n",
       "13                      1.0  \n",
       "16                      1.0  \n",
       "15                      1.0  \n",
       "18                      1.0  \n",
       "17                      1.0  \n",
       "19                      1.0  \n",
       "121                     1.0  \n",
       "3                       1.0  \n",
       "123                     1.0  \n",
       "20                      1.0  \n",
       "117                     1.0  \n",
       "119                     1.0  \n",
       "116                     1.0  \n",
       "118                     1.0  \n",
       "125                     1.0  \n",
       "21                      1.0  \n",
       "22                      1.0  \n",
       "120                     1.0  \n",
       "24                      1.0  \n",
       "23                      1.0  \n",
       "25                      1.0  \n",
       "26                      1.0  \n",
       "27                      1.0  \n",
       "..                      ...  \n",
       "102                     1.0  \n",
       "101                     1.0  \n",
       "104                     1.0  \n",
       "99                      1.0  \n",
       "90                      1.0  \n",
       "91                      1.0  \n",
       "92                      1.0  \n",
       "87                      1.0  \n",
       "100                     1.0  \n",
       "86                      1.0  \n",
       "85                      1.0  \n",
       "89                      1.0  \n",
       "84                      1.0  \n",
       "93                      1.0  \n",
       "94                      1.0  \n",
       "95                      1.0  \n",
       "96                      1.0  \n",
       "97                      1.0  \n",
       "98                      1.0  \n",
       "88                      1.0  \n",
       "108                     1.0  \n",
       "2                       1.0  \n",
       "109                     1.0  \n",
       "127                     1.0  \n",
       "110                     1.0  \n",
       "113                     1.0  \n",
       "112                     1.0  \n",
       "111                     1.0  \n",
       "115                     1.0  \n",
       "114                     1.0  \n",
       "\n",
       "[128 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "\n",
    "leaderboard = ai.get_leaderboard(apiurl, username, password, aws_key, aws_password, region)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
